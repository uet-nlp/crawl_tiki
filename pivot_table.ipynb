{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import dateutil\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, precision_recall_curve\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier, GBTClassifier, RandomForestClassificationModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "from ext.DAC_utils import DAC_utils\n",
    "from dac_automl.autotuning.classification_model_selector import ClassificationModelSelector\n",
    "\n",
    "spark = SparkSession.builder.appName('DHTSDCT').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pyspark.sql import SparkSession, DataFrameWriter\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as types\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.ml.stat import Summarizer\n",
    "from functools import reduce\n",
    "spark = SparkSession.builder.config('hive.stats.autogather', \"false\").appName(\"prod_c360_transformation\").getOrCreate()\n",
    "sc =spark.sparkContext\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "partition = range(20210302, 20210330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "for i in partition:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "for item in range(20210301, 20210331):\n",
    "    base = sqlContext.sql(''' INSERT OVERWRITE TABLE tmp_myvt_ecommerce_daily PARTITION (partition = '{}')\n",
    "SELECT DISTINCT msisdn, myvt_cat\n",
    "FROM tmp_myvt_ecommerce_daily_v2\n",
    "WHERE partition = {}\n",
    "'''.format(item,item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "for item in range(20210310, 20210315):\n",
    "    base = sqlContext.sql(''' INSERT into TABLE tmp_myvt_ecommerce_daily_v4 PARTITION (partition = '{}')\n",
    "SELECT distinct msisdn, \n",
    "\tCASE WHEN lower(hostname) rlike 'vexere|pasoto|baolau|click1bus|futabus' then 'VEXERE'\n",
    "\t\tWHEN lower(hostname) rlike 'shemarookids|bookboxinc' THEN 'MONKEYJUNIOR'\n",
    "\t\tWHEN lower(hostname) rlike 'speaking24.com' THEN 'ELSASPEAK'\n",
    "\tEND AS myvt_cat\n",
    "FROM f_detail_url_https\n",
    "WHERE \tpartition='{}' and lower(hostname) rlike 'vexere|pasoto|baolau|click1bus|futabus|shemarookids|speaking24.com|bookboxinc'\n",
    "'''.format(item,item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "for item in range(20210307, 20210310):\n",
    "    base = sqlContext.sql(''' INSERT into TABLE tmp_myvt_ecommerce_daily_v4 PARTITION (partition = '{}')\n",
    "SELECT distinct msisdn, \n",
    "\tCASE WHEN lower(hostname) rlike 'vexere|pasoto|baolau|click1bus|futabus' then 'VEXERE'\n",
    "\t\tWHEN lower(hostname) rlike 'shemarookids|bookboxinc' THEN 'MONKEYJUNIOR'\n",
    "\t\tWHEN lower(hostname) rlike 'speaking24.com' THEN 'ELSASPEAK'\n",
    "\tEND AS myvt_cat\n",
    "FROM f_detail_url_https\n",
    "WHERE \tpartition='{}' and lower(hostname) rlike 'vexere|pasoto|baolau|click1bus|futabus|shemarookids|speaking24.com|bookboxinc'\n",
    "'''.format(item,item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "    base = sqlContext.sql(''' INSERT into TABLE tmp_myvt_ecommerce_daily_v4 PARTITION (partition = '{}' )\n",
    "SELECT distinct msisdn, \n",
    "\tCASE WHEN lower(hostname) rlike 'kynaforkids.vn|teacher.scholastic.com|pbskids.org|starfall.com|earnenglishkids.britishcouncil.org|bookboxinc|raz-kids.com|busybeavers.com|shemarookids|britishcouncil.vn|funbrain.com|breakingnewsenglish.com|literactive.com|highlightskids.com|tienganh.monkey.edu.vn|monkeyjunior.vn' THEN 'MONKEYJUNIOR'\n",
    "\t\tWHEN lower(hostname) rlike 'khanacademy.org|hoctoantienganh.com|patrickjmt.com|wolframalpha.com|onlinemathlearning.com|math.com|happymath.vn|cth.edu.vn|contuhoc.com|blog.e2.com.vn|gmaths.edu.vn|monkeymath.vn|conhocgioi.com' THEN 'MONKEYMATH'\n",
    "\t\tWHEN lower(hostname) rlike 'studytienganh.vn|starfall.com|turtlediary.comkids-stories.html|english-online.at|reading.ecb.org|esl-bits.net|mightybook.com|pbskids.org|monkeystories.vn' THEN 'MONKEYSTORIES'\n",
    "\t\tWHEN lower(hostname) rlike 'elsaspeak.vn|apollo.edu.vn|tienganhmoingay.com|mshoagiaotiep.com|anhnguoxford.vn|britishcouncil.vn|elllo.org|funeasyenglish.com|go4english.com|lang-8.com|busuu.com|rosettastone.com|vocabsushi.com|learnenglish.de|examenglish.com|duolingo.com|memrise.com|e-space.vn|speaking24.com|learnenglish.britishcouncil.org' THEN 'ELSASPEAK'\n",
    "\t\tWHEN lower(hostname) rlike 'vexere|pasoto|baolau|click1bus|futabus|xeca|vexegiare|megabus|saolimousine|xedcarlimousine|xekhachgiare|tongdai-datxe|xekhachanphuquy|vetaugiare24h|saodieu|easybook|tongdaixekhacanhbuoi|sanvh|xethexe' THEN 'VEXERE'\n",
    "\tEND AS myvt_cat\n",
    "FROM f_detail_url_https\n",
    "WHERE \tpartition='{}' and lower(hostname) rlike 'kynaforkids.vn|teacher.scholastic.com|pbskids.org|starfall.com|earnenglishkids.britishcouncil.org|bookboxinc|raz-kids.com|busybeavers.com|shemarookids|britishcouncil.vn|funbrain.com|breakingnewsenglish.com|literactive.com|highlightskids.com|tienganh.monkey.edu.vn|monkeyjunior.vn|khanacademy.org|hoctoantienganh.com|patrickjmt.com|wolframalpha.com|onlinemathlearning.com|math.com|happymath.vn|cth.edu.vn|contuhoc.com|blog.e2.com.vn|gmaths.edu.vn|monkeymath.vn|conhocgioi.com|studytienganh.vn|starfall.com|turtlediary.comkids-stories.html|english-online.at|reading.ecb.org|esl-bits.net|mightybook.com|pbskids.org|monkeystories.vn|elsaspeak.vn|apollo.edu.vn|tienganhmoingay.com|mshoagiaotiep.com|anhnguoxford.vn|britishcouncil.vn|elllo.org|funeasyenglish.com|go4english.com|lang-8.com|busuu.com|rosettastone.com|vocabsushi.com|learnenglish.de|examenglish.com|duolingo.com|memrise.com|e-space.vn|speaking24.com|learnenglish.britishcouncil.orgen|vexere|pasoto|baolau|click1bus|futabus|xeca|vexegiare|megabus|saolimousine|xedcarlimousine|xekhachgiare|tongdai-datxe|xekhachanphuquy|vetaugiare24h|saodieu|easybook|tongdaixekhacanhbuoi|sanvh|xethexe'\n",
    "'''.format(20210305,20210305))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "for item in range(20210304, 20210306):\n",
    "    base = sqlContext.sql(''' INSERT into TABLE tmp_myvt_ecommerce_daily_v4 PARTITION (partition = '{}')\n",
    "SELECT distinct msisdn, \n",
    "\tCASE WHEN lower(hostname) rlike 'vexere|pasoto|baolau|click1bus|futabus' then 'VEXERE'\n",
    "\t\tWHEN lower(hostname) rlike 'shemarookids|bookboxinc' THEN 'MONKEYJUNIOR'\n",
    "\t\tWHEN lower(hostname) rlike 'speaking24.com' THEN 'ELSASPEAK'\n",
    "\tEND AS myvt_cat\n",
    "FROM f_detail_url_https\n",
    "WHERE \tpartition='{}' and lower(hostname) rlike 'vexere|pasoto|baolau|click1bus|futabus|shemarookids|speaking24.com|bookboxinc'\n",
    "'''.format(item,item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "base = sqlContext.sql(''' INSERT into TABLE tmp_myvt_ecommerce_daily_v4 PARTITION (partition = '20210304')\n",
    "SELECT distinct msisdn, \n",
    "\tCASE WHEN lower(hostname) rlike 'vexere|pasoto|baolau|click1bus|futabus' then 'VEXERE'\n",
    "\t\tWHEN lower(hostname) rlike 'shemarookids|bookboxinc' THEN 'MONKEYJUNIOR'\n",
    "\t\tWHEN lower(hostname) rlike 'speaking24.com' THEN 'ELSASPEAK'\n",
    "\tEND AS myvt_cat\n",
    "FROM f_detail_url_https\n",
    "WHERE \tpartition='20210304' and lower(hostname) rlike 'vexere|pasoto|baolau|click1bus|futabus|shemarookids|speaking24.com|bookboxinc'\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "def get_pivot_tbl(table_dim, table_log, table_out = None, table_out_path = None, time_in_queue = None):\n",
    "    '''Sinh bảng c360\n",
    "    :table_dim: str: tên bảng danh mục, phải bao gồm các cột category, is_pivot_category\n",
    "    :table_log: str: tên bảng log summary theo ngày. Định danh thuê bao phải là ISDN\n",
    "    :table_out: str: tên bảng xoay ngang, PK là isdn, có các thông tin \n",
    "    :time_in_queue: datetime: ngày chạy dữ liệu mong muốn, dạng datetime.datetime.strptime('20200105', '%Y%m%d')'''\n",
    "    if table_out_path is None:\n",
    "        table_out_path = '/work_zone/upsell_vas/adp_new/tmp'\n",
    "    if time_in_queue is None:\n",
    "        time_in_queue = datetime.datetime.now()\n",
    "    partition_inday = time_in_queue.strftime('%Y%m%d')\n",
    "    partition_today = ( time_in_queue - datetime.timedelta(days = 1)).strftime('%Y%m%d')\n",
    "    partition_firstday = (time_in_queue - datetime.timedelta(days = 1) ).strftime('%Y%m01')\n",
    "\n",
    "    pddf_dims = sqlContext.sql('from '+ table_dim).toPandas()\n",
    "    df_log = sqlContext.sql('from '+ table_log + ' where partition >= \"{}\"and partition <=\"{}\"'.format(partition_firstday,partition_today)) # <--- fix this\n",
    "    # df_log = sqlContext.sql('from '+ table_log + ' where partition >= 20210201 and partition <=20210401') # <--- fix this\n",
    "\n",
    "    # Danh mục category cần pivot\n",
    "    l_cat_to_pivot    = list( np.unique( pddf_dims[ (pddf_dims['is_pivot_category'] == '1') & (pddf_dims['category'] != '') ]['category'].sort_values().str.lower() ) )\n",
    "    # Danh mục sub_category cần pivot\n",
    "    l_subcat_to_pivot = list( np.unique( pddf_dims[ (pddf_dims['is_pivot_sub_categoryf'] == '1') & (pddf_dims['sub_category'] != '') ]['sub_category'].str.lower() ) )\n",
    "    # Danh mục function cần pivot\n",
    "    l_func_to_pivot   = list( np.unique( pddf_dims[ (pddf_dims['is_pivot_function'] == '1') & (pddf_dims['function'] != '')]['function'].str.lower() ) )\n",
    "    \n",
    "    # Group ISDN \n",
    "    grb_isdn = df_log.groupby(['isdn'])\n",
    "\n",
    "    # PIVOT\n",
    "    df_cat_pv = grb_isdn.pivot('category', l_cat_to_pivot).agg(F.sum('lognum').alias('cat_lognum'),F.sum('dnum').alias('cat_dnum') )\n",
    "    df_subcat_pv = grb_isdn.pivot('sub_category', l_subcat_to_pivot).agg(F.sum('lognum').alias('subcat_lognum'),F.sum('dnum').alias('subcat_dnum') )\n",
    "    df_fn_pv = grb_isdn.pivot('function', l_func_to_pivot).agg(F.sum('lognum').alias('fn_lognum'),F.sum('dnum').alias('fn_dnum') )\n",
    "\n",
    "    # JOIN 3 TABLE \n",
    "    df_full = df_cat_pv.fillna(0).join(df_subcat_pv.fillna(0), on ='isdn', how = 'left').join(df_fn_pv.fillna(0), on = 'isdn', how = 'left')\n",
    " \n",
    "    if table_out is not None:\n",
    "        df_full.createOrReplaceTempView(\"tmp_vas_mytempTable\")\n",
    "        # Khởi tạo schema nếu không tìm thấy\n",
    "        try:\n",
    "\n",
    "            df = spark.sql('from '+ table_out)\n",
    " \n",
    "        except:\n",
    "\n",
    "            cols = [col for col in df_full.columns if col != 'isdn']\n",
    "            cols2 = []\n",
    "            for i in range(len(cols)):\n",
    "                column = cols[i].replace(' ', '_')\n",
    "                cols2.append(column)\n",
    "                \n",
    "            cols_list = ','.join([' isdn string '] + [col + ' bigint ' for col in cols2 if col != 'isdn'] ) + ', last_update string comment \"ngày cập nhật gần nhất \"'\n",
    "            sql_create_tbl_schema = \"\"\"\n",
    "                CREATE EXTERNAL TABLE IF NOT EXISTS `{0}` \n",
    "                ({1})\n",
    "                partitioned by (partition string comment 'tháng phát sinh log, định dạng YYYYMM01, ghi vào ngày DD-1')\n",
    "                STORED AS parquet\n",
    "                LOCATION '{2}/{0}'\n",
    "                tblproperties (\"parquet.compression\" = \"SNAPPY\")\"\"\".format(table_out, cols_list, table_out_path)\n",
    "            # print(sql_create_tbl_schema)\n",
    "            sqlContext.sql(sql_create_tbl_schema)\n",
    "\n",
    "        # Ghi dữ liệu vào bảng\n",
    "        sqlContext.sql('INSERT OVERWRITE TABLE '+ table_out +' PARTITION (partition = {0}) select *, {1} as last_update from tmp_vas_mytempTable'.format(partition_firstday, partition_inday))\n",
    "    return df_full\n",
    "    \n",
    "def _rename_column(df, newColumns):\n",
    "    '''Đổi tên của 1 df thành tên cột mới\n",
    "    :df: dataframe: bảng dữ liệu cần đổi\n",
    "    :newColumns: tên columns mới\n",
    "    \n",
    "    return:df: dataframe đầu ra'''\n",
    "    oldColumns = df.columns \n",
    "    mapping = dict(zip(oldColumns, newColumns))\n",
    "    return df.select([F.col(c).alias(mapping.get(c, c)) for c in oldColumns])\n",
    "    \n",
    "def get_windowing_v2(tbl_pivoted, tbl_windowed, id_cols = ['isdn', 'partition', 'last_update'], partition_cur = None, partition_pre = None, table_windowed_path = 'work_zone/upsell_vas/tmp', time_in_queue = None, is_write= True):\n",
    "    ''' Tạo dataframe windowing từ bảng pivoted\n",
    "    :tbl_pivoted: string: tên bảng pivoted\n",
    "    :tbl_windowed: str: tên bảng đầu ra \n",
    "    :id_cols: list of string: tên cột ID không windowing\n",
    "    :partition_cur: str, yyyymm01: partition tháng n, tháng ghi vào partition của windowed table\n",
    "    :partition_pre: str, yyyymm01: partition tháng n-1, tháng ghi vào partition của windowed table\n",
    "    :table_windowed_path: str: đường dẫn lưu tên bảng (phải không có / ở cuối)\n",
    "    '''\n",
    "    date_current = datetime.datetime.now().strftime('%Y%m%d')\n",
    "    if time_in_queue is None:\n",
    "        time_in_queue = datetime.datetime.now()\n",
    "\n",
    "    if partition_pre is None and partition_cur is None:\n",
    "        partition_cur = ( time_in_queue - datetime.timedelta(days = 1) ).strftime('%Y%m01')\n",
    "        partition_pre = ( time_in_queue - datetime.timedelta(days = 32) ).strftime('%Y%m01')\n",
    "    \n",
    "    # pivoted dataframe\n",
    "    df_p_cur = sqlContext.sql(\"FROM %s WHERE partition = %s\"%(tbl_pivoted, partition_cur))\n",
    "    cols_p_selected = [col for col in df_p_cur.columns if col not in id_cols or col == 'isdn']\n",
    "    df_p_cur_selected = df_p_cur[cols_p_selected]\n",
    "\n",
    "    try:\n",
    "        # Nếu đã có bảng thì lấy partition pre\n",
    "        df_w_pre = sqlContext.sql(\"FROM %s WHERE partition = %s\"%(tbl_windowed, partition_pre))\n",
    "    except:\n",
    "        # Nếu chưa có thì tạo schema (dataframe rỗng)\n",
    "        schema_left_id_column = [types.StructField( 'isdn' , types.StringType(), False )]\n",
    "        schema_mid_tupple = [\n",
    "            (\n",
    "                struct, \n",
    "                types.StructField( struct.name + '_n_1', struct.dataType, struct.nullable ),\n",
    "                types.StructField( struct.name + '_n_2', struct.dataType, struct.nullable ),\n",
    "                types.StructField( struct.name + '_n_3', struct.dataType, struct.nullable )\n",
    "            )\n",
    "        for struct in df_p_cur.schema\n",
    "        if struct.name not in id_cols\n",
    "        ]\n",
    "        schema_mid = [struct for tup in schema_mid_tupple for struct in tup]\n",
    "        schema_right_id_column = [  types.StructField( 'last_update' , types.StringType(), False ),\n",
    "                                    types.StructField( 'partition' , types.StringType(), False )]\n",
    "        schema = schema_left_id_column + schema_mid + schema_right_id_column\n",
    "\n",
    "        df_w_pre = spark.createDataFrame(spark.sparkContext.emptyRDD(), types.StructType(schema) )\n",
    "        # Lưu thành bảng\n",
    "        (\n",
    "            df_w_pre\n",
    "            .write\n",
    "            .format('parquet')\n",
    "            .option(\"path\", table_windowed_path + '/'+ tbl_windowed)\n",
    "            .option(\"compression\", \"snappy\")\n",
    "            .partitionBy(\"partition\")\n",
    "            .mode(\"overwrite\").saveAsTable( tbl_windowed)\n",
    "        )\n",
    "\n",
    "    # rename previous partition columns\n",
    "    cols_w_selected = ['isdn'] + [col for col in df_w_pre.columns if col[-4:] != '_n_3' and col not in id_cols]\n",
    "    newColumns_w_pre = ['isdn'] + [col for col in df_w_pre.columns if col[-4:-1] == '_n_'] # Lấy tên của các cột _n_ để ghi vào các cột tịnh tiến timeframe\n",
    "\n",
    "    df_w_pre_selected = df_w_pre[cols_w_selected]\n",
    "    df_w_pre_rename = _rename_column(df_w_pre_selected, newColumns_w_pre)\n",
    "\n",
    "    # Concat to get final dataframe\n",
    "    df_final = df_p_cur_selected.join(df_w_pre_rename, on = 'isdn', how = 'full')\n",
    "    df_final = df_final.withColumn('last_update', F.lit(date_current))\n",
    "    df_final = df_final.withColumn('partition', F.lit(partition_cur))\n",
    "\n",
    "    columns_with_ordered = df_w_pre.columns\n",
    "\n",
    "    df_final2 = df_final[columns_with_ordered].drop('partition').fillna(0)\n",
    "    table_tmp_path = '/work_zone/upsell_vas/adp_new/vas'\n",
    "    if is_write:\n",
    "        spark.conf.set( \"spark.sql.sources.partitionOverwriteMode\", \"dynamic\" )\n",
    "        spark.conf.set( \"hive.exec.dynamic.partition.mode\", \"nonstrict\" )\n",
    "        df_final2.createOrReplaceTempView('tmp_table_c360_at')\n",
    "        ( # save result to a tmp table \n",
    "            df_final2.write\n",
    "            .format('parquet')\n",
    "            .option(\"path\", table_tmp_path + '/tmp/tmp_to_overwrite_partition_of_table_' + tbl_windowed)\n",
    "            .option(\"compression\", \"snappy\")\n",
    "            # .partitionBy(\"partition\")\n",
    "            .mode(\"overwrite\").saveAsTable( 'tmp_to_overwrite_partition_of_table_'+tbl_windowed)\n",
    "        )\n",
    "        spark.sql('refresh table tmp_to_overwrite_partition_of_table_{}'.format(tbl_windowed))\n",
    "        sqlContext.sql('INSERT OVERWRITE TABLE %s PARTITION (partition = %s) FROM tmp_to_overwrite_partition_of_table_%s'%(tbl_windowed,partition_cur, tbl_windowed))\n",
    "\n",
    "    return df_final2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_full = get_pivot_tbl('d_myvtcdr_mapping', 'f_myvt_payment_summary_by_function_mon', table_out = 'f_myvt_payment_summary_by_function_pivoted_mon',table_out_path ='/work_zone/upsell_vas/adp_new/vas/tmp', time_in_queue = datetime.datetime.strptime('20210103', '%Y%m%d') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "a = spark.sql('from f_myvt_payment_summary_by_function_pivoted_mon limit 10')\n",
    "a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "a = get_windowing_v2('f_myvt_payment_summary_by_function_pivoted_mon', \n",
    "                'f_myvt_payment_summary_by_function_windowed_mon', id_cols = ['isdn', 'partition', 'last_update'], partition_cur = '20210401', partition_pre = '20210301', \n",
    "                table_windowed_path = '/work_zone/upsell_vas/adp_new/tmp', time_in_queue = None, is_write= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
